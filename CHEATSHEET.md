# Understanding the Vaya Transportation Assistant

## What This Project Is About

This is a transportation assistant that uses multiple AI systems working together to help people with travel questions. It's built using a special architecture called "Agent-to-Agent" (A2A) where different AI programs communicate through a shared information space to solve problems.

## The Main Idea: How Multiple AIs Work Together

Instead of having one big AI that tries to do everything, this project uses three specialized AI programs that each have their own job. They communicate with each other using a shared "blackboard" (called WorldState) where they write down what they've learned and what needs to be done next.

Here's how it works:
1. **User asks a question** ‚Üí "What's the weather in Miami?"
2. **Planning AI** figures out what steps are needed
3. **Action AI** does the actual work (calls weather APIs, finds locations)
4. **Chat AI** takes all the information and gives a nice answer

## Current Architecture: Single-Threaded Multi-Agent System

**Important Clarification:** While this is technically a multi-agent system with three distinct agents, the current implementation is **sequential** (not parallel). The agents work one after another, not simultaneously. Here's why:

### Why Sequential Execution?
- **Simple and reliable**: Easier to debug and understand
- **State consistency**: No race conditions between agents
- **Resource efficiency**: Uses less memory and API calls
- **Predictable behavior**: Each step completes before the next begins

### Future Possibilities for Parallel Execution
The architecture *could* be extended to support parallel processing:
- **Independent API calls**: Weather for multiple cities could run simultaneously
- **Async execution**: Using Python's `asyncio` for concurrent operations
- **Multiple executors**: Specialized executors for different types of tasks

## Agent-to-Agent (A2A) Communication: Yes, It's Still A2A!

**Yes, this is absolutely still A2A architecture**, even with a shared WorldState. Here's why:

### What Makes It A2A?
1. **Decentralized decision-making**: Each agent makes its own decisions based on the current state
2. **Peer communication**: Agents communicate through the shared WorldState (the "blackboard pattern")
3. **Autonomous operation**: Each agent can operate independently once it has the information it needs
4. **Dynamic coordination**: Agents can respond to changes in the WorldState made by other agents

### WorldState as Communication Medium
The WorldState acts like a shared bulletin board:
- **Planning Agent** writes: "Here's the plan - execute these steps"
- **Execution Agent** reads the plan and writes: "Step 1 completed, results here"
- **Synthesis Agent** reads the results and writes: "Final response ready"
- **Coordinator** monitors the board and manages the overall process

This is actually a **classic A2A pattern** used in many multi-agent systems!

## The Three Main AI Programs (Agents)

### 1. The Planning Agent (`agents/agents.py` - PlanningAgent class)

**What it does:** This is like the project manager of the team. It reads what the user wants and creates a step-by-step plan.

**How it works:**
- Gets the user's question from the WorldState
- Uses simple rules to decide what needs to be done:
  - If user says "weather", it plans to get location and weather data
  - If user says "where am I", it plans to get current location
  - If user just says "hi", it plans to use the conversation tool
- Creates a plan as a list of steps (like "Step 1: Find location", "Step 2: Get weather")
- If something goes wrong, it can change the plan

**Key code parts:**
```python
# This checks if the user is just chatting
casual_phrases = ["hi", "hello", "hey", "how are you", "what's up"]
is_casual = any(phrase in query_text for phrase in casual_phrases)
if is_casual:
    # Create a simple plan with just the conversation tool
    plan = {"steps": [{"id": "S1", "action": "Conversation", "args": {"message": query}}]}
```

### 2. The Execution Agent (`agents/agents.py` - ExecutionAgent class)

**What it does:** This is the worker bee that actually gets things done. It takes the plan from the Planning Agent and executes it step by step.

**Current Implementation:** Sequential execution (one step at a time)
- Gets the plan from the Planning Agent
- For each step in the plan, it calls the right tool:
  - "Geolocate" ‚Üí calls Google Maps to find current location
  - "Geocode" ‚Üí calls Google Maps to find a specific place
  - "Weather" ‚Üí calls Google Weather API
  - "Conversation" ‚Üí uses the conversation tool for casual talk
- Each tool returns data that gets stored in the WorldState
- Moves to the next step only after the current one completes

**Why sequential?** It ensures reliability and makes debugging easier. Each step must complete successfully before the next begins.

### 1. The Planning Agent (`agents/agents.py` - PlanningAgent class)

**What it does:** This is like the project manager of the team. It reads what the user wants and creates a step-by-step plan.

**How it works:**
- Gets the user's question from the WorldState
- Uses simple rules to decide what needs to be done:
  - If user says "weather", it plans to get location and weather data
  - If user says "where am I", it plans to get current location
  - If user just says "hi", it plans to use the conversation tool
- Creates a plan as a list of steps (like "Step 1: Find location", "Step 2: Get weather")
- If something goes wrong, it can change the plan

**Key code parts:**
```python
# This checks if the user is just chatting
casual_phrases = ["hi", "hello", "hey", "how are you", "what's up"]
is_casual = any(phrase in query_text for phrase in casual_phrases)
if is_casual:
    # Create a simple plan with just the conversation tool
    plan = {"steps": [{"id": "S1", "action": "Conversation", "args": {"message": query}}]}
```

### 2. The Execution Agent (`agents/agents.py` - ExecutionAgent class)

**What it does:** This is the worker bee that actually gets things done. It takes the plan from the Planning Agent and makes it happen.

**How it works:**
- Gets the plan from the Planning Agent
- For each step in the plan, it calls the right tool:
  - "Geolocate" ‚Üí calls Google Maps to find current location
  - "Geocode" ‚Üí calls Google Maps to find a specific place
  - "Weather" ‚Üí calls Google Weather API
  - "Conversation" ‚Üí uses the conversation tool for casual talk
- Each tool returns data that gets stored in the WorldState
- If a step fails, it records the error

**Key code parts:**
```python
# This is how it decides which tool to use
if action == "Geolocate":
    return self._execute_geolocate()
elif action == "Weather":
    return self._execute_weather(args, world_state)
elif action == "Conversation":
    return self._execute_conversation(args.get("message", ""))
```

### 3. The Synthesis Agent (`agents/agents.py` - SynthesisAgent class)

**What it does:** This is the friendly explainer that takes all the raw data and turns it into a nice, helpful answer for the user.

**How it works:**
- Waits until all the work is done (all steps completed)
- Looks at all the data collected (weather info, locations, conversation responses)
- Uses either simple rules or an AI language model to create a response
- For weather: "It's 75¬∞F and sunny in Miami"
- For conversation: "Hello! I'm here to help with transportation questions"

**Key code parts:**
```python
# Check if we have conversation data ready to use
conversation_response = world_state.context.get("conversation_response", {})
if conversation_response.get("response_text"):
    return {
        "deltaState": {
            "context": {
                "final_response": conversation_response["response_text"]
            }
        }
    }
```

## How The Agents Talk To Each Other

The agents don't talk directly to each other. Instead, they all read from and write to the same "WorldState" object. It's like a shared notebook where:

- **Planning Agent writes:** "Here's the plan - do these 3 steps"
- **Execution Agent reads:** "Okay, I see the plan, let me do step 1"
- **Execution Agent writes:** "Step 1 is done, here's the weather data"
- **Synthesis Agent reads:** "I see all steps are done and we have weather data"
- **Synthesis Agent writes:** "Here's the final answer for the user"

## Addressing Architecture Questions

### Is It Really Multi-Agent With Only One Executor?

**Yes, it is still a multi-agent system**, but with a **centralized execution model**. Here's the breakdown:

**Current Agent Count:**
- **1 Planning Agent** - Creates and manages plans
- **1 Execution Agent** - Executes all the actual work
- **1 Synthesis Agent** - Creates final responses
- **1 Coordinator** - Manages the overall process

**Why This Design?**
1. **Simplicity**: One executor is easier to manage and debug
2. **Consistency**: All execution goes through the same logic and error handling
3. **Resource Efficiency**: Less overhead than multiple executors
4. **State Management**: Single executor means no coordination issues between multiple workers

### Why Sequential Execution (Not Parallel)?

**Current Implementation:** The Execution Agent processes steps one at a time:
```python
# In agents/agents.py - ExecutionAgent.process()
for step in steps:
    if step["id"] not in completed:
        result = execute_step(step)
        # Only move to next step after this one completes
```

**Why Sequential?**
1. **API Rate Limits**: Many APIs have request limits that parallel calls would exceed
2. **Error Handling**: Easier to handle failures when steps are isolated
3. **State Consistency**: No race conditions between concurrent operations
4. **Debugging**: Clear execution order makes problems easier to trace

**When Parallel Could Help:**
- **Independent operations**: Getting weather for multiple cities simultaneously
- **Different APIs**: Calling Google Maps and Weather APIs at the same time
- **Batch processing**: Multiple similar requests that don't depend on each other

**How Parallel Could Work:**
```python
# Future implementation possibility
async def execute_parallel(steps):
    tasks = []
    for step in steps:
        if is_independent(step):  # Check if step can run in parallel
            tasks.append(asyncio.create_task(execute_step_async(step)))
    
    results = await asyncio.gather(*tasks)
    return results
```

### Is WorldState Still "Agent-to-Agent" Communication?

**Absolutely yes!** The WorldState is actually the **classic implementation** of A2A communication:

**Traditional A2A:** Agents send direct messages to each other
**WorldState A2A:** Agents read/write to a shared information space

**Why WorldState is Still A2A:**
1. **Decentralized Control**: Each agent makes its own decisions
2. **Autonomous Operation**: Agents work independently based on available information
3. **Dynamic Coordination**: Agents respond to changes made by others
4. **Shared Understanding**: All agents have access to the same information

**Real-World Analogy:**
- **Traditional A2A**: Like teammates passing notes in class
- **WorldState A2A**: Like writing on a shared whiteboard that everyone can read

This pattern is used in many production multi-agent systems because it:
- Scales better than direct messaging
- Provides natural load balancing
- Makes the system more resilient to individual agent failures

## The Tools That Do The Real Work

### Location Tools (`agents/tools/location_tool.py`)

**Geolocate Tool:** Uses Google Maps to find where the user is right now
```python
@tool("Geolocate")
def geolocate_user() -> dict:
    # Calls Google's geolocation API
    # Returns: {"slots": {"origin": {"lat": 25.7617, "lng": -80.1918, "name": "Miami, FL"}}}
```

**Geocode Tool:** Finds the coordinates of a place name
```python
@tool("Geocode")
def geocode_place(address: str) -> dict:
    # Calls Google Maps geocoding API
    # Input: "Miami, FL"
    # Returns: {"slots": {"origin": {"lat": 25.7617, "lng": -80.1918, "name": "Miami, FL"}}}
```

### Weather Tool (`agents/tools/weather_tool.py`)

**Weather Tool:** Gets current weather for any location
```python
@tool("Weather")
def weather_current(lat: float, lng: float, units: str = "IMPERIAL") -> dict:
    # Calls Google Weather API
    # Input: lat=25.7617, lng=-80.1918
    # Returns: {"context": {"lastWeather": {"temp": 75, "summary": "sunny", "humidity": 60}}}
```

### Conversation Tool (`agents/tools/conversation_tool.py`)

**Conversation Tool:** Handles casual talk and redirects to transportation
```python
@tool("Conversation")
def handle_conversation(message: str) -> dict:
    # Input: "hi how are you"
    # Returns: {"context": {"conversation_response": {"response_text": "Hello! I'm your transportation assistant..."}}}
```

## The Main Program That Starts Everything

### `main.py` - The Entry Point

This is the first file that runs when you type `python main.py`. It:

1. **Sets up the system:**
   - Loads environment variables (API keys)
   - Creates the three agents
   - Sets up the coordinator that manages them

2. **Runs the chat loop:**
   - Shows the welcome message
   - Waits for user input
   - Sends questions to the A2A system
   - Shows the responses

3. **Handles special commands:**
   - "exit" or "quit" ‚Üí ends the program
   - "reset" ‚Üí clears memory
   - "memory" ‚Üí shows conversation history

### `agents/coordinator.py` - The Traffic Controller

This file manages the three agents and makes sure they work together properly:

- **Starts the conversation process** when user asks a question
- **Tells agents when to work** (planning ‚Üí execution ‚Üí synthesis)
- **Handles replanning** if something goes wrong
- **Manages memory** of the conversation
- **Coordinates the message passing** between agents

## How A Conversation Actually Works

Let's trace through what happens when user says "What's the weather in Miami?":

1. **User Input** ‚Üí `main.py` gets "What's the weather in Miami?"

2. **Coordinator Starts** ‚Üí `coordinator.py` creates WorldState with the question

3. **Planning Phase:**
   - PlanningAgent reads: "What's the weather in Miami?"
   - Recognizes this needs location + weather
   - Creates plan: Step 1 = Geocode "Miami", Step 2 = Get Weather

4. **Execution Phase:**
   - ExecutionAgent reads the plan
   - Runs Geocode tool ‚Üí finds Miami coordinates
   - Runs Weather tool ‚Üí gets weather data
   - Writes results to WorldState

5. **Synthesis Phase:**
   - SynthesisAgent sees all steps are done
   - Reads weather data from WorldState
   - Creates nice response: "It's 75¬∞F and sunny in Miami"

6. **Response** ‚Üí Coordinator sends final answer back to user

## The Data Structures That Hold Everything

### WorldState (`utils/contracts.py`)

This is the main data structure that holds everything:

```python
class WorldState(BaseModel):
    meta: Dict[str, Any] = {"sessionId": None, "version": "2.0"}
    user: Dict[str, Any] = {"locale": "en-US"}
    query: Dict[str, Any] = {"raw": ""}  # The user's question
    slots: Slots = Field(default_factory=Slots)  # Location data
    context: Dict[str, Any] = {  # Shared information
        "plan": {"steps": [], "status": "none"},
        "completed_steps": [],
        "lastWeather": {},
        "conversation_response": {}
    }
    evidence: Dict[str, Any] = Field(default_factory=dict)
    errors: List[str] = Field(default_factory=list)
    memory: Dict[str, Any] = Field(default_factory=dict)
```

### Slots Structure

```python
class Slots(BaseModel):
    origin: Dict[str, Any] = {"name": None, "lat": None, "lng": None}
    destination: Dict[str, Any] = {"name": None, "lat": None, "lng": None}
    departureTime: Optional[str] = None
    modePrefs: List[str] = []
```

## Error Handling and Recovery

The system is designed to handle problems gracefully:

1. **API Failures:** If Google Maps is down, the error gets recorded and the system tries to continue
2. **Invalid Input:** If user asks something unclear, the conversation tool handles it
3. **Replanning:** If a step fails, the Planning Agent can create a new plan
4. **Fallback Responses:** If everything fails, there are backup responses

## Key Design Principles

1. **Separation of Concerns:** Each agent has one job (plan, execute, synthesize)
2. **Shared State:** All agents read/write to the same WorldState
3. **Tool-Based Actions:** Real work is done by specialized tools
4. **Error Resilience:** System continues working even when parts fail
5. **Memory Persistence:** Conversations are saved and can be resumed

## How To Run and Test The System

### Basic Setup:
```bash
# Install dependencies
pip install -r requirements.txt

# Set up API keys in .env file
GEMINI_API_KEY=your_gemini_key
GOOGLE_API_KEY=your_google_key

# Run the system
python main.py
```

### Testing Different Scenarios:
- **Weather:** "What's the weather in Miami?"
- **Location:** "Where am I?"
- **Conversation:** "Hi how are you?"
- **Multi-step:** "What's the weather in Miami and New York?"

This architecture makes the system reliable, maintainable, and easy to understand because each part has a clear job and they work together through the shared WorldState.

## File Structure and Organization

The project is organized into clear folders that separate different types of code:

### `/agents/` - The AI Programs
- **`agents.py`** - Contains the three main agent classes (PlanningAgent, ExecutionAgent, SynthesisAgent)
- **`coordinator.py`** - Manages communication between agents
- **`/tools/`** - Contains the specialized tools that do actual work:
  - `weather_tool.py` - Gets weather data from Google APIs
  - `location_tool.py` - Handles location services (geocoding, reverse geocoding)
  - `conversation_tool.py` - Handles casual conversation

### `/utils/` - Helper Code
- **`contracts.py`** - Defines data structures (WorldState, Slots, etc.)
- **`state.py`** - Functions for merging data updates
- **`logger.py`** - Logging system for debugging and monitoring

### `/data/` - Persistent Storage
- **`conversation_memory.json`** - Saves conversation history between sessions

### `/logs/` - System Logs
- **`app.log`** - Records all system activity for debugging

### Root Files
- **`main.py`** - Entry point that starts the chat interface
- **`requirements.txt`** - Lists all Python packages needed
- **`README.md`** - Project documentation

## Understanding the Data Flow

### Normal Request Flow:
1. **User Input** ‚Üí `main.py` receives the message
2. **Coordinator** ‚Üí `coordinator.py` creates WorldState and starts the process
3. **Planning** ‚Üí PlanningAgent analyzes the request and creates a plan
4. **Execution** ‚Üí ExecutionAgent runs each step using the appropriate tools
5. **Synthesis** ‚Üí SynthesisAgent creates the final response
6. **Output** ‚Üí Response goes back to user through `main.py`

### Error Handling Flow:
1. **Detection** ‚Üí Any agent/tool detects a problem
2. **Recording** ‚Üí Error gets added to `world_state.errors`
3. **Recovery** ‚Üí Coordinator may trigger replanning
4. **Fallback** ‚Üí SynthesisAgent provides helpful error message
5. **Logging** ‚Üí Everything gets recorded in `logs/app.log`

## Key Design Patterns Used

### 1. Agent-to-Agent (A2A) Communication
Instead of one big AI trying to do everything, the system uses specialized agents that communicate through shared state. This makes the system:
- More reliable (one agent failing doesn't break everything)
- Easier to maintain (each agent has a clear job)
- More flexible (new agents can be added easily)

### 2. Tool-Based Architecture
Real work is done by specialized tools rather than the agents themselves. This separates:
- **Decision making** (agents decide what to do)
- **Action execution** (tools do the actual work)
- **Response generation** (agents format the results)

### 3. Shared State Pattern
All agents read from and write to the same WorldState object. This provides:
- **Consistency** - all agents see the same information
- **Persistence** - state survives between agent interactions
- **Debugging** - easy to see what happened at each step

### 4. Error Resilience
The system is designed to continue working even when parts fail:
- API calls might fail, but the system tries alternatives
- Invalid input gets handled gracefully
- Failed steps get logged but don't stop the whole process

## Common Development Tasks

### Adding a New Tool:
1. Create new file in `agents/tools/`
2. Use `@tool("ToolName")` decorator
3. Return data in WorldState-compatible format
4. Add tool to ExecutionAgent's action handling
5. Update PlanningAgent to create plans using the new tool

### Adding a New Agent:
1. Create new agent class in `agents/agents.py`
2. Implement required methods (`can_handle`, `process`)
3. Register agent in `main.py` coordinator setup
4. Update coordinator logic if needed

### Debugging Issues:
1. Check `logs/app.log` for error messages
2. Look at WorldState dumps in memory
3. Test individual tools with direct function calls
4. Use the `status` command to see system state

## Testing and Quality Assurance

### Unit Testing:
- Test individual tools with mock API responses
- Test agent logic with controlled WorldState inputs
- Verify error handling with simulated failures

### Integration Testing:
- Test complete conversation flows
- Verify agent communication works correctly
- Test memory persistence across sessions

### Manual Testing Scenarios:
- Weather queries for different locations
- Location-based questions
- Casual conversation handling
- Error conditions (invalid locations, API failures)
- Multi-step requests (weather for multiple cities)

This architecture makes the system both powerful and maintainable. Each component has a clear responsibility, and they work together through well-defined interfaces and shared state management.
You: weather in Miami

# Use special commands
You: /status
You: /memory
You: /reset
```

---

## üõ†Ô∏è How to Set Up Vaya (For Beginners)

### Step 1: Get the Ingredients
```bash
# Install Python stuff (like getting cooking ingredients)
pip install -r requirements.txt
```

### Step 2: Get Your Keys
```bash
# You need special passwords for Google services
# Create a .env file with:
GEMINI_API_KEY=your_gemini_key_here
GOOGLE_API_KEY=your_google_key_here
```

### Step 3: Start Talking!
```bash
# Start the conversation
python main.py

# Ask anything!
You: weather in Miami
You: where am I
You: directions to airport
```

---

### Why Agent-to-Agent (A2A) Architecture?

The A2A approach was chosen over traditional single-agent systems because:

1. **Modularity**: Each agent has a clear, focused responsibility
2. **Reliability**: If one agent fails, others can continue working
3. **Scalability**: New agents can be added without rewriting existing code
4. **Debugging**: Easier to isolate and fix problems in specific agents
5. **Testing**: Each agent can be tested independently

### Shared State vs Direct Communication

Instead of agents talking directly to each other, they use a shared WorldState because:

1. **Consistency**: All agents see the same information at the same time
2. **Persistence**: State survives between agent interactions
3. **Debugging**: Easy to inspect the complete system state at any point
4. **Flexibility**: New agents can be added without changing existing communication patterns

### Tool-Based Execution

The system separates planning (what to do) from execution (how to do it) because:

1. **Reusability**: Tools can be used by different agents or even other systems
2. **Testing**: Tools can be tested independently with mock inputs
3. **Maintenance**: API changes only affect the specific tool, not the agent logic
4. **Performance**: Tools can be optimized independently


